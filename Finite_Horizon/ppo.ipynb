{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ray.rllib.agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ppo\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mppo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPOTrainer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ray.rllib.agents'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "import torch\n",
    "from ray.rllib.agents.ppo import ppo\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "# from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "from ray.tune import register_env\n",
    "from games.base import MeanFieldGame\n",
    "from games.mfg_wrapper import MFGGymWrapper\n",
    "from simulator.mean_fields.base import MeanField\n",
    "from solver.base import Solver\n",
    "from solver.policy.finite_policy import FiniteFeedbackPolicy\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "from solver.policy.random_policy import RandomFinitePolicy\n",
    "from solver.stoc_reg_omd_graphon_solver import stoc_reg_DiscretizedGraphonExactOMDSolverFinite\n",
    "from solver.stoc_reg_omd_graphon_solver_2 import stoc_reg_DiscretizedGraphonExactOMDSolverFinite_2\n",
    "from solver.reg_omd_graphon_solver import reg_DiscretizedGraphonExactOMDSolverFinite\n",
    "from solver.omd_graphon_solver import DiscretizedGraphonExactOMDSolverFinite\n",
    "from solver.reg_graphon_solver import reg_DiscretizedGraphonExactSolverFinite\n",
    "from solver.graphon_solver import DiscretizedGraphonExactSolverFinite\n",
    "from evaluator.graphon_evaluator import DiscretizedGraphonEvaluatorFinite\n",
    "from evaluator.reg_graphon_evaluator import reg_DiscretizedGraphonEvaluatorFinite\n",
    "from evaluator.stochastic_evaluator import StochasticEvaluator\n",
    "from games.finite.beach import BeachGraphon\n",
    "from games.finite.cyber import CyberGraphon\n",
    "from games.finite.cyber_het import HeterogeneousCyberGraphon\n",
    "from games.finite.investment import InvestmentGraphon\n",
    "from games.finite.sis import SISGraphon\n",
    "from games.graphons import uniform_attachment_graphon, er_graphon, ranked_attachment_graphon, power_law_graphon, cutoff_power_law_graphon, sbm_graphon, exp_graphon\n",
    "from simulator.graphon_simulator import DiscretizedGraphonExactSimulatorFinite\n",
    "from simulator.stochastic_simulator import StochasticSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization = 1 \n",
    "num_alphas = 30\n",
    "game = BeachGraphon(**{\"graphon\": exp_graphon})\n",
    "simulator = DiscretizedGraphonExactSimulatorFinite(**{})\n",
    "evaluator = reg_DiscretizedGraphonEvaluatorFinite(**{'regularization':regularization,'num_alphas':num_alphas})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to solve the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def env_creator(env_config=None):\n",
    "            return MFGGymWrapper(game, None, time_obs_augment=True)\n",
    "\n",
    "register_env(\"MFG-v0\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 20:20:18,377\tWARNING ppo.py:141 -- `train_batch_size` (4000) cannot be achieved with your other settings (num_workers=6 num_envs_per_worker=1 rollout_fragment_length=200)! Auto-adjusting `rollout_fragment_length` to 666.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 20:20:25,202\tWARNING trainer_template.py:185 -- `execution_plan` functions should accept `trainer`, `workers`, and `config` as args!\n",
      "2024-04-19 20:20:25,205\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "trainer = ppo.PPOTrainer(env=\"MFG-v0\", config={\n",
    "            'num_workers': 6,\n",
    "            \"gamma\": 1,\n",
    "            \"entropy_coeff\": 0.01,\n",
    "            \"clip_param\": 0.2,\n",
    "            \"kl_target\": 0.006,\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/agents/trainer.py:670\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    669\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# allow logs messages to propagate\u001b[39;00m\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/agents/trainer.py:656\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m MAX_WORKER_FAILURE_RETRIES):\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 656\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mTrainable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_worker_failures\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/tune/trainable.py:248\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs one logical iteration of training.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mCalls ``step()`` internally. Subclasses should override ``step()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    A dict that describes training progress.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 248\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep() needs to return a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/agents/trainer_template.py:206\u001b[0m, in \u001b[0;36mbuild_trainer.<locals>.trainer_cls.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluate_this_iter:\n\u001b[0;32m--> 206\u001b[0m     step_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_exec_impl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# We have to evaluate in this training iteration.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# No parallelism.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:756\u001b[0m, in \u001b[0;36mLocalIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once()\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilt_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(AttributeError)",
     "evalue": "\u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983638, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f1363deea30>)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n    return next(self.local_it)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n    yield self.sample()\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n    batches = [self.input_reader.next()]\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n    batches = [self.get_data()]\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n    item = next(self._env_runner)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n    base_env.send_actions(actions_to_send)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n    self.vector_env.vector_step(action_vector)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n    obs, r, done, info = self.envs[i].step(actions[i])\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n    p=self.transition_probs(t, x, u, mu)).item()])\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n    return NeighborhoodMeanField(mu.state_space, self.graphon)\nAttributeError: 'NoneType' object has no attribute 'state_space'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(AttributeError)\u001b[0m              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     log \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoop \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m mean \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ent \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(iteration, log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_reward_mean\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      7\u001b[0m                                                 log[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault_policy\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/agents/trainer.py:667\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorker crashed during call to train(). To attempt to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinue training without the failed worker, set \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    666\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_worker_failures\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 667\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    669\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)  \u001b[38;5;66;03m# allow logs messages to propagate\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/agents/trainer.py:656\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m MAX_WORKER_FAILURE_RETRIES):\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 656\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mTrainable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RayError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_worker_failures\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/tune/trainable.py:248\u001b[0m, in \u001b[0;36mTrainable.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs one logical iteration of training.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03mCalls ``step()`` internally. Subclasses should override ``step()``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m    A dict that describes training progress.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 248\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep() needs to return a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/agents/trainer_template.py:206\u001b[0m, in \u001b[0;36mbuild_trainer.<locals>.trainer_cls.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluate_this_iter:\n\u001b[0;32m--> 206\u001b[0m     step_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_exec_impl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# We have to evaluate in this training iteration.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;66;03m# No parallelism.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_parallel_to_training\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:756\u001b[0m, in \u001b[0;36mLocalIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_once()\n\u001b[0;32m--> 756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilt_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:843\u001b[0m, in \u001b[0;36mLocalIterator.filter.<locals>.apply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_filter\u001b[39m(it):\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    844\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_context():\n\u001b[1;32m    845\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady) \u001b[38;5;129;01mor\u001b[39;00m fn(item):\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:843\u001b[0m, in \u001b[0;36mLocalIterator.filter.<locals>.apply_filter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_filter\u001b[39m(it):\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    844\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metrics_context():\n\u001b[1;32m    845\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady) \u001b[38;5;129;01mor\u001b[39;00m fn(item):\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "    \u001b[0;31m[... skipping similar frames: LocalIterator.for_each.<locals>.apply_foreach at line 783 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:876\u001b[0m, in \u001b[0;36mLocalIterator.flatten.<locals>.apply_flatten\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_flatten\u001b[39m(it):\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    877\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    878\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "    \u001b[0;31m[... skipping similar frames: LocalIterator.for_each.<locals>.apply_foreach at line 783 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:783\u001b[0m, in \u001b[0;36mLocalIterator.for_each.<locals>.apply_foreach\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_foreach\u001b[39m(it):\n\u001b[0;32m--> 783\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, _NextValueNotReady):\n\u001b[1;32m    785\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py:471\u001b[0m, in \u001b[0;36mParallelIterator.batch_across_shards.<locals>.base_iterator\u001b[0;34m(timeout)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m active:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [a\u001b[38;5;241m.\u001b[39mpar_iter_next\u001b[38;5;241m.\u001b[39mremote() \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m active]\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;66;03m# Always yield after each round of gets with timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:89\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/ray/worker.py:1621\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     worker\u001b[38;5;241m.\u001b[39mcore_worker\u001b[38;5;241m.\u001b[39mdump_object_store_memory_usage()\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayTaskError):\n\u001b[0;32m-> 1621\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mas_instanceof_cause()\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[0;31mRayTaskError(AttributeError)\u001b[0m: \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983638, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f1363deea30>)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n    return next(self.local_it)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n    yield self.sample()\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n    batches = [self.input_reader.next()]\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n    batches = [self.get_data()]\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n    item = next(self._env_runner)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n    base_env.send_actions(actions_to_send)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n    self.vector_env.vector_step(action_vector)\n  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n    obs, r, done, info = self.envs[i].step(actions[i])\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n    p=self.transition_probs(t, x, u, mu)).item()])\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n    return NeighborhoodMeanField(mu.state_space, self.graphon)\nAttributeError: 'NoneType' object has no attribute 'state_space'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 20:21:32,667\tERROR worker.py:79 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983639, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb86027fa30>)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n",
      "    self.vector_env.vector_step(action_vector)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n",
      "    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n",
      "    p=self.transition_probs(t, x, u, mu)).item()])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n",
      "    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n",
      "    return NeighborhoodMeanField(mu.state_space, self.graphon)\n",
      "AttributeError: 'NoneType' object has no attribute 'state_space'\n",
      "2024-04-19 20:21:32,669\tERROR worker.py:79 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983640, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f52fb5a4a30>)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n",
      "    self.vector_env.vector_step(action_vector)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n",
      "    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n",
      "    p=self.transition_probs(t, x, u, mu)).item()])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n",
      "    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n",
      "    return NeighborhoodMeanField(mu.state_space, self.graphon)\n",
      "AttributeError: 'NoneType' object has no attribute 'state_space'\n",
      "2024-04-19 20:21:32,670\tERROR worker.py:79 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983643, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f4b9e5eea30>)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n",
      "    self.vector_env.vector_step(action_vector)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n",
      "    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n",
      "    p=self.transition_probs(t, x, u, mu)).item()])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n",
      "    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n",
      "    return NeighborhoodMeanField(mu.state_space, self.graphon)\n",
      "AttributeError: 'NoneType' object has no attribute 'state_space'\n",
      "2024-04-19 20:21:32,672\tERROR worker.py:79 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983642, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f91df41ca30>)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n",
      "    self.vector_env.vector_step(action_vector)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n",
      "    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n",
      "    p=self.transition_probs(t, x, u, mu)).item()])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n",
      "    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n",
      "    return NeighborhoodMeanField(mu.state_space, self.graphon)\n",
      "AttributeError: 'NoneType' object has no attribute 'state_space'\n",
      "2024-04-19 20:21:32,673\tERROR worker.py:79 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::RolloutWorker.par_iter_next()\u001b[39m (pid=3983641, ip=10.1.102.239, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f8bd1e7fa30>)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/util/iter.py\", line 1151, in par_iter_next\n",
      "    return next(self.local_it)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 377, in gen_rollouts\n",
      "    yield self.sample()\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 752, in sample\n",
      "    batches = [self.input_reader.next()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 103, in next\n",
      "    batches = [self.get_data()]\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 233, in get_data\n",
      "    item = next(self._env_runner)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/evaluation/sampler.py\", line 648, in _env_runner\n",
      "    base_env.send_actions(actions_to_send)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/base_env.py\", line 365, in send_actions\n",
      "    self.vector_env.vector_step(action_vector)\n",
      "  File \"/home/bcl/.conda/envs/py39/lib/python3.9/site-packages/ray/rllib/env/vector_env.py\", line 173, in vector_step\n",
      "    obs, r, done, info = self.envs[i].step(actions[i])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/mfg_wrapper.py\", line 42, in step\n",
      "    next_state = self.mfg.next_state(self.t, self.x, u, self.mu)\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 45, in next_state\n",
      "    p=self.transition_probs(t, x, u, mu)).item()])\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 88, in transition_probs\n",
      "    return self.transition_probs_g(t, x, u, self.get_neighborhood_mf(t, x, u, mu))\n",
      "  File \"/home/bcl/guojunyu/gmfg/Finite_Horizon/games/graphon_mfg.py\", line 64, in get_neighborhood_mf\n",
      "    return NeighborhoodMeanField(mu.state_space, self.graphon)\n",
      "AttributeError: 'NoneType' object has no attribute 'state_space'\n"
     ]
    }
   ],
   "source": [
    "logs = []\n",
    "verbose = True \n",
    "for iteration in range(20):\n",
    "    log = trainer.train()\n",
    "    if verbose:\n",
    "        print(\"Loop {} mean {} ent {}\".format(iteration, log['episode_reward_mean'],\n",
    "                                                log['info']['learner']['default_policy']['entropy']))\n",
    "    logs.append(log)\n",
    "checkpoint = trainer.save()\n",
    "trainer.load_checkpoint(checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
